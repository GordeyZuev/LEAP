# Architecture Decision Records - Features

**–ü—Ä–æ–µ–∫—Ç:** LEAP Platform
**–í–µ—Ä—Å–∏—è:** 2.0 (–ê–∫—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: —è–Ω–≤–∞—Ä—å 2026)
**–°—Ç–∞—Ç—É—Å:** Production Features

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [ADR-010: Automation System](#adr-010-automation-system)
2. [ADR-011: Async Processing (Celery)](#adr-011-async-processing-celery)
3. [ADR-012: Quotas & Subscriptions](#adr-012-quotas--subscriptions)
4. [ADR-013: Audit Logging](#adr-013-audit-logging)
5. [ADR-014: Notifications](#adr-014-notifications)
6. [ADR-015: FSM –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏](#adr-015-fsm-–¥–ª—è-–Ω–∞–¥–µ–∂–Ω–æ–π-–æ–±—Ä–∞–±–æ—Ç–∫–∏)
7. [ADR-016: Database Performance Optimization](#adr-016-database-performance-optimization)

---

## ADR-010: Automation System

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
**–î–∞—Ç–∞:** –Ø–Ω–≤–∞—Ä—å 2026

### –†–µ—à–µ–Ω–∏–µ

Template-driven automation —Å scheduled jobs —á–µ—Ä–µ–∑ Celery Beat.

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Automation Architecture          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

automation_jobs (schedule config)
    ‚Üì
Celery Beat (scheduler)
    ‚Üì
Celery Worker (execution)
    ‚Üì
1. Sync sources ‚Üí find new recordings
2. Match to templates ‚Üí auto-assign
3. Process matched recordings
4. Upload to platforms
```

### –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

**1. Automation Jobs (database):**
```python
class AutomationJob:
    name: str
    schedule_config: dict  # Cron-like config
    template_id: int       # Template to apply
    enabled: bool
    last_run_at: datetime
    next_run_at: datetime
```

**2. Schedule Types:**
```python
{
  "type": "daily",       # Daily at specific time
  "time": "06:00",
  "timezone": "UTC"
}

{
  "type": "hours",       # Every N hours
  "hours": 6
}

{
  "type": "weekdays",    # Specific days + time
  "days": [1, 3, 5],     # Mon, Wed, Fri
  "time": "08:00"
}

{
  "type": "cron",        # Custom cron
  "expression": "0 */6 * * *"
}
```

**3. Execution Flow:**
```python
async def execute_automation_job(job_id: int):
    """
    1. Sync sources linked to template
    2. Find recordings with template_id
    3. Filter by status (INITIALIZED, etc.)
    4. Trigger full pipeline
    5. Track progress in processing_stages
    """
    job = await get_job(job_id)
    template = await get_template(job.template_id)

    # Sync
    new_recordings = await sync_sources(template.source_ids)

    # Filter + Process
    to_process = await filter_recordings(
        template_id=template.id,
        status="INITIALIZED",
        exclude_blank=True
    )

    # Batch process
    await bulk_process_recordings(to_process)
```

### Quota Management

**Limits:**
- `max_automation_jobs` - –º–∞–∫—Å. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ jobs (–ø–æ –ø–ª–∞–Ω—É)
- `min_job_interval` - –º–∏–Ω. –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏ (anti-spam)

**Checks:**
```python
# Before creating job
if user.jobs_count >= plan.max_automation_jobs:
    raise QuotaExceededError("Max automation jobs reached")

# Before running
if job.last_run_at + min_interval > now():
    skip_run("Too frequent")
```

### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

**–§–∞–π–ª—ã:**
- `database/automation_models.py` - AutomationJob, ProcessingStage
- `api/routers/automation.py` - CRUD endpoints
- `api/tasks/automation.py` - Celery tasks
- `api/services/automation_service.py` - logic

**Endpoints:**
- `GET /automation/jobs` - list jobs
- `POST /automation/jobs` - create job
- `PATCH /automation/jobs/{id}` - update job
- `DELETE /automation/jobs/{id}` - delete job
- `POST /automation/jobs/{id}/run` - manual trigger
- `POST /automation/jobs/{id}/dry-run` - preview

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ

**–°–º. —Ç–∞–∫–∂–µ:** [TECHNICAL.md](TECHNICAL.md) - Automation system implementation

---

## ADR-011: Async Processing (Celery)

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
**–î–∞—Ç–∞:** –Ø–Ω–≤–∞—Ä—å 2026

### –†–µ—à–µ–Ω–∏–µ

Celery + Redis –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á.

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Celery Architecture              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

FastAPI ‚Üí Celery Task ‚Üí Redis (broker)
             ‚Üì
        Celery Worker (3 workers)
             ‚Üì
        Processing (CPU: 2 workers)
        Upload (I/O: 1 worker)
        Automation (1 worker)
             ‚Üì
        Result ‚Üí Redis (backend)
             ‚Üì
        Client polls task status
```

### Queues

**Queue Structure:**
```
processing:    Video processing (FFmpeg, heavy CPU)
upload:        API calls to YouTube/VK (I/O bound)
automation:    Scheduled jobs (Celery Beat)
```

**Worker Configuration:**
```bash
# Processing worker (CPU-intensive)
celery -A api.celery_app worker \
  --queues=processing \
  --concurrency=2 \
  --pool=prefork \
  --max-tasks-per-child=5

# Upload worker (I/O-intensive)
celery -A api.celery_app worker \
  --queues=upload \
  --concurrency=4 \
  --pool=gevent

# Automation worker
celery -A api.celery_app worker \
  --queues=automation \
  --concurrency=1
```

### Task Types

**Processing Tasks:**
- `download_recording_task` - download from source
- `process_video_task` - FFmpeg processing
- `transcribe_recording_task` - AI transcription
- `extract_topics_task` - AI topic extraction
- `generate_subtitles_task` - SRT/VTT generation

**Upload Tasks:**
- `upload_to_platform_task` - upload to YouTube/VK
- `retry_failed_uploads_task` - retry failed

**Batch Tasks:**
- `bulk_process_recordings_task` - batch processing
- `bulk_sync_sources_task` - batch sync

**Automation Tasks:**
- `execute_automation_job_task` - run scheduled job

### Progress Tracking

**Task Status:**
```python
{
  "task_id": "abc-123",
  "status": "PROCESSING",  # PENDING, PROCESSING, SUCCESS, FAILURE
  "progress": 45,          # 0-100%
  "current_step": "Transcribing audio...",
  "result": None,          # Result when complete
  "error": None            # Error message if failed
}
```

**API:**
```
GET /tasks/{task_id} - Get task status
DELETE /tasks/{task_id} - Cancel task
GET /tasks - List user's tasks
```

### Celery Chains –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ (—è–Ω–≤–∞—Ä—å 2026)

**–ü—Ä–æ–±–ª–µ–º–∞:** –ú–æ–Ω–æ–ª–∏—Ç–Ω—ã–π `process_recording_task` –±–ª–æ–∫–∏—Ä–æ–≤–∞–ª worker –Ω–∞ 5+ –º–∏–Ω—É—Ç.

**–†–µ—à–µ–Ω–∏–µ:** Orchestrator pattern —Å Celery chains:

```python
# Orchestrator (~0.08s)
process_recording_task(recording_id, user_id)
  ‚îî‚îÄ chain.apply_async() ‚Üí –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç worker
       ‚îî‚îÄ download ‚Üí trim ‚Üí transcribe ‚Üí topics ‚Üí subs ‚Üí launch_uploads
          (–∫–∞–∂–¥—ã–π —à–∞–≥ –Ω–∞ –ª—é–±–æ–º —Å–≤–æ–±–æ–¥–Ω–æ–º worker)
```

**Benefits:**
- Worker –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç—Å—è –∑–∞ 0.08s (–Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –Ω–∞ 5+ –º–∏–Ω—É—Ç)
- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã—Ö recordings
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —à–∞–≥–æ–≤ –º–µ–∂–¥—É workers
- Worker reuse - –æ–¥–∏–Ω worker –º–æ–∂–µ—Ç –¥–µ–ª–∞—Ç—å download –¥–ª—è rec A, –ø–æ—Ç–æ–º trim –¥–ª—è rec B

**Graceful Error Handling (—è–Ω–≤–∞—Ä—å 2026):**
- Credential/Token/Resource errors –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è gracefully
- Output target –ø–æ–º–µ—á–∞–µ—Ç—Å—è –∫–∞–∫ FAILED –≤ –ë–î
- –ó–∞–¥–∞—á–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç `status='failed'` –≤–º–µ—Å—Ç–æ raise
- ERROR –ª–æ–≥–∏—Ä—É–µ—Ç—Å—è –±–µ–∑ traceback spam
- Celery –≤–∏–¥–∏—Ç –∑–∞–¥–∞—á—É –∫–∞–∫ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—É—é

### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

**–§–∞–π–ª—ã:**
- `api/celery_app.py` - Celery config
- `api/tasks/` - task definitions (6 —Ñ–∞–π–ª–æ–≤)
- `api/services/task_service.py` - task management
- `docker-compose.yml` - Redis + Celery services

**Monitoring:**
- Flower UI: `http://localhost:5555`
- Prometheus metrics (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ

---

## ADR-012: Quotas & Subscriptions

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
**–î–∞—Ç–∞:** –§–µ–≤—Ä–∞–ª—å 2026

### –†–µ—à–µ–Ω–∏–µ

Code-based defaults + optional plan subscriptions —Å usage tracking –∏ user statistics.

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Quota & Stats System             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

DEFAULT_QUOTAS (config/settings.py, all None = unlimited)
    ‚Üì
subscription_plans (optional, for custom limits)
    ‚Üì
user_subscriptions (user ‚Üê plan + custom overrides)
    ‚Üì
quota_usage (tracking –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º YYYYMM)

StatsService ‚Üí recordings, transcription seconds, storage bytes
```

### Default Behavior

–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –ø–æ–ª—É—á–∞—é—Ç `DEFAULT_QUOTAS` –∏–∑ `config/settings.py`:
```python
DEFAULT_QUOTAS: dict[str, int | None] = {
    "max_recordings_per_month": None,   # None = unlimited
    "max_storage_gb": None,
    "max_concurrent_tasks": None,
    "max_automation_jobs": None,
    "min_automation_interval_hours": None,
}
```

- –ü–æ–¥–ø–∏—Å–∫–∞ –ù–ï —Å–æ–∑–¥–∞—ë—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
- –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞–∑–Ω–∞—á–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤—Ä—É—á–Ω—É—é (–∫–∞—Å—Ç–æ–º–Ω—ã–π –ø–ª–∞–Ω)
- –ü—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –ø–æ–¥–ø–∏—Å–∫–∏ ‚Üí fallback –Ω–∞ `DEFAULT_QUOTAS`

### Quota Types

**Resource Quotas:**
```python
{
  "max_recordings_per_month": 50,      # Monthly limit (None = unlimited)
  "max_storage_gb": 25,                # Total storage
  "max_concurrent_tasks": 2,           # Parallel processing
  "max_automation_jobs": 3,            # Scheduled jobs
  "min_automation_interval_hours": 1   # Min automation interval
}
```

**Custom Overrides (per user):**
```python
# Override via user_subscriptions.custom_max_*
{
  "custom_max_recordings_per_month": 100,  # Override plan: 50 ‚Üí 100
  "custom_max_storage_gb": 50              # Override plan: 25 ‚Üí 50
}
```

### Usage Tracking

**Period-based tracking (quota_usage):**
```python
{
  "user_id": "01HQ...",
  "period": "202602",  # YYYYMM
  "recordings_count": 15,
  "storage_bytes": 3435973837,
  "concurrent_tasks_count": 2
}
```

**Quota Checks (middleware):**
```python
# QuotaService.get_effective_quotas:
# 1. Get user subscription (if exists)
# 2. Get plan limits + custom overrides
# 3. If no subscription ‚Üí return DEFAULT_QUOTAS
# 4. None = unlimited, skip check

# Before creating recording:
await check_recordings_quota(user_id)
await check_storage_quota(user_id, user_slug)
```

### User Stats

**StatsService** –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É:
- `recordings_total` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π (—Ñ–∏–ª—å—Ç—Ä—É–µ—Ç—Å—è –ø–æ –¥–∞—Ç–∞–º)
- `recordings_by_status` ‚Äî —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
- `recordings_by_template` ‚Äî –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –ø–æ —à–∞–±–ª–æ–Ω–∞–º
- `transcription_total_seconds` ‚Äî —Å—É–º–º–∞ `final_duration`
- `storage_bytes` / `storage_gb` ‚Äî —Ä–∞–∑–º–µ—Ä –ø–∞–ø–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

### Endpoints

```
GET /users/me/quota - Current quota status
GET /users/me/stats - User statistics (recordings, transcription, storage)
GET /admin/stats/overview - Platform stats
GET /admin/stats/users - User stats
GET /admin/stats/quotas - Quota usage
POST /admin/users/{id}/quota - Override quota
```

### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

**–§–∞–π–ª—ã:**
- `config/settings.py` - `DEFAULT_QUOTAS` constant
- `database/auth_models.py` - subscription & quota models (3 tables)
- `api/services/quota_service.py` - quota logic (fallback ‚Üí DEFAULT_QUOTAS)
- `api/services/stats_service.py` - user statistics
- `api/middleware/quota.py` - enforcement checks
- `api/routers/admin.py` - admin endpoints
- `api/routers/users.py` - /me/quota, /me/stats

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ


---

## ADR-013: Audit Logging

**–°—Ç–∞—Ç—É—Å:** üöß –ß–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (–±–∞–∑–æ–≤—ã–π logging)
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** Medium (–¥–ª—è compliance)

### –†–µ—à–µ–Ω–∏–µ

Structured logging + audit trail –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π.

### –ß—Ç–æ –ª–æ–≥–∏—Ä—É–µ—Ç—Å—è

**Critical Operations:**
- Authentication (login, logout, token refresh)
- Credential management (create, update, delete)
- Recording operations (create, delete, reset)
- Template changes (create, update, delete, rematch)
- Quota overrides (admin actions)
- Automation job runs (start, end, errors)

**Audit Log Format:**
```python
{
  "timestamp": "2026-01-14T10:30:00Z",
  "user_id": 123,
  "action": "recording.delete",
  "resource_type": "recording",
  "resource_id": 456,
  "ip_address": "192.168.1.1",
  "user_agent": "Mozilla/5.0...",
  "details": {
    "recording_name": "Lecture 1",
    "status": "UPLOADED"
  },
  "result": "success"  # success, failure, partial
}
```

### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è (—Ç–µ–∫—É—â–∞—è)

**Structured Logging:**
- Python `logging` module
- JSON format –¥–ª—è production
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Rotation: daily, 30 days retention

**–ë—É–¥—É—â–µ–µ (–ø–æ–ª–Ω—ã–π audit):**
```sql
CREATE TABLE audit_logs (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    user_id INT REFERENCES users(id),
    action VARCHAR(100),
    resource_type VARCHAR(50),
    resource_id INT,
    ip_address INET,
    user_agent TEXT,
    details JSONB,
    result VARCHAR(20)
);

CREATE INDEX idx_audit_user ON audit_logs(user_id, timestamp DESC);
CREATE INDEX idx_audit_action ON audit_logs(action, timestamp DESC);
CREATE INDEX idx_audit_resource ON audit_logs(resource_type, resource_id);
```

**Endpoints (–±—É–¥—É—â–µ–µ):**
```
GET /admin/audit - Admin audit log
GET /users/me/activity - User activity log
```

**–°—Ç–∞—Ç—É—Å:** üöß –ë–∞–∑–æ–≤—ã–π logging —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω, –ø–æ–ª–Ω—ã–π audit - TODO

---

## ADR-014: Notifications

**–°—Ç–∞—Ç—É—Å:** üöß –ß–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (error logging)
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** Low (nice to have)

### –†–µ—à–µ–Ω–∏–µ

Multi-channel notifications –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π.

### Notification Types

**Error Notifications:**
- Processing failure after retries
- Transcription failure (quota, API error)
- Upload failure (auth, quota, network)
- Automation job failure

**Success Notifications (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):**
- Recording uploaded successfully
- Automation job completed
- Daily/weekly summary

**Quota Notifications:**
- 80% quota reached
- 100% quota reached
- Overage usage

### Channels

**Email (primary):**
- SMTP integration
- Template-based messages
- HTML + plain text fallback

**Webhook (future):**
- POST to user-defined URL
- JSON payload with event data
- Retry logic with exponential backoff

**In-app (future):**
- Notification center –≤ UI
- Real-time via WebSocket
- Persistent storage –≤ –ë–î

### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è (—Ç–µ–∫—É—â–∞—è)

**Error Logging:**
- –í—Å–µ –æ—à–∏–±–∫–∏ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è
- Email —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è - TODO

**–ë—É–¥—É—â–µ–µ:**
```python
# Notification Service
class NotificationService:
    async def send_error_notification(
        user_id: int,
        error_type: str,
        details: dict
    ):
        # Send via configured channels
        pass

    async def send_quota_warning(
        user_id: int,
        quota_type: str,
        usage_percent: float
    ):
        pass
```

**–°—Ç–∞—Ç—É—Å:** üöß –ë–∞–∑–æ–≤—ã–π logging, notifications - TODO

---

## ADR-015: FSM –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
**–î–∞—Ç–∞:** –Ø–Ω–≤–∞—Ä—å 2026

### –†–µ—à–µ–Ω–∏–µ

Finite State Machine –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö state transitions.

### FSM Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Processing State Machine         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

INITIALIZED
    ‚Üì
DOWNLOADING ‚Üí DOWNLOADED
    ‚Üì
PROCESSING ‚Üí PROCESSED
    ‚Üì
TRANSCRIBING ‚Üí TRANSCRIBED
    ‚Üì
UPLOADING ‚Üí UPLOADED

Any state ‚Üí FAILED (with failed_at_stage)
FAILED ‚Üí retry ‚Üí continue from failed stage
```

### State Definitions

**Processing States:**
- `INITIALIZED` - –ó–∞–ø–∏—Å—å —Å–æ–∑–¥–∞–Ω–∞, –≥–æ—Ç–æ–≤–∞ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ
- `DOWNLOADING` - –°–∫–∞—á–∏–≤–∞–µ—Ç—Å—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
- `DOWNLOADED` - –°–∫–∞—á–∞–Ω–∞, –≥–æ—Ç–æ–≤–∞ –∫ processing
- `PROCESSING` - FFmpeg –æ–±—Ä–∞–±–æ—Ç–∫–∞ (trim silence)
- `PROCESSED` - –û–±—Ä–∞–±–æ—Ç–∞–Ω–∞, –≥–æ—Ç–æ–≤–∞ –∫ transcription
- `TRANSCRIBING` - AI —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
- `TRANSCRIBED` - –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–∞, –≥–æ—Ç–æ–≤–∞ –∫ upload
- `UPLOADING` - –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
- `UPLOADED` - –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤–µ–∑–¥–µ
- `FAILED` - –û—à–∏–±–∫–∞ (—Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Å—Ç–∞–¥–∏–∏)
- `SKIPPED` - –ü—Ä–æ–ø—É—â–µ–Ω–∞ (blank record, user skip)

### Transition Rules

**Allowed Transitions:**
```python
ALLOWED_TRANSITIONS = {
    "PENDING_SOURCE": ["INITIALIZED", "SKIPPED"],  # After source processing completes
    "INITIALIZED": ["DOWNLOADING", "FAILED", "SKIPPED"],
    "DOWNLOADING": ["DOWNLOADED", "FAILED"],
    "DOWNLOADED": ["PROCESSING", "FAILED"],
    "PROCESSING": ["PROCESSED", "FAILED"],
    "PROCESSED": ["TRANSCRIBING", "FAILED"],
    "TRANSCRIBING": ["TRANSCRIBED", "FAILED"],
    "TRANSCRIBED": ["UPLOADING", "FAILED"],
    "UPLOADING": ["UPLOADED", "FAILED"],
    "UPLOADED": [],  # Terminal state
    "FAILED": ["DOWNLOADING", "PROCESSING", "TRANSCRIBING", "UPLOADING"],  # Retry
    "SKIPPED": []  # Terminal state
}
```

**Validation:**
```python
def validate_transition(from_status: str, to_status: str) -> bool:
    """Check if transition is allowed"""
    return to_status in ALLOWED_TRANSITIONS[from_status]

# Usage
if not validate_transition(recording.status, new_status):
    raise InvalidTransitionError(f"{recording.status} ‚Üí {new_status}")
```

### Output Target FSM

**Separate FSM –¥–ª—è –∫–∞–∂–¥–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã:**
```python
class OutputTarget:
    target_type: str  # youtube, vk
    status: TargetStatus  # Enum

    # Transitions
    NOT_UPLOADED ‚Üí UPLOADING ‚Üí UPLOADED
    NOT_UPLOADED ‚Üí FAILED
    UPLOADING ‚Üí FAILED
    FAILED ‚Üí UPLOADING  # Retry
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ù–µ–∑–∞–≤–∏—Å–∏–º—ã–µ —Å—Ç–∞—Ç—É—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
- ‚úÖ Partial success (YouTube ok, VK failed)
- ‚úÖ Retry —Ç–æ–ª—å–∫–æ failed platforms

### Failed Handling

**Failed Flag:**
```python
class Recording:
    status: ProcessingStatus  # Current stage
    failed: bool              # Is in failed state?
    failed_at_stage: str      # Stage where failed
    retry_count: int          # Number of retries
    error_message: str        # Last error
```

**Retry Logic:**
```python
async def retry_recording(recording_id: int):
    """
    1. Check failed=True
    2. Get failed_at_stage
    3. Reset failed=False
    4. Continue from failed_at_stage
    5. Increment retry_count
    """
    recording = await get_recording(recording_id)

    if not recording.failed:
        raise ValueError("Recording not failed")

    # Continue from failed stage
    stage = recording.failed_at_stage
    recording.failed = False
    recording.retry_count += 1

    if stage == "DOWNLOADING":
        await download_task(recording_id)
    elif stage == "PROCESSING":
        await process_task(recording_id)
    # etc.
```

### Processing Stages Tracking

**Table: processing_stages**
```python
class ProcessingStage:
    recording_id: int
    stage_name: str  # download, process, transcribe, upload
    status: str      # pending, running, completed, failed
    started_at: datetime
    completed_at: datetime
    error_message: str
    metadata: dict   # Stage-specific data
```

**Usage:**
- –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ progress
- Debugging failed recordings
- Analytics (avg time per stage)

### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

**–§–∞–π–ª—ã:**
- `models/recording.py` - ProcessingStatus enum
- `database/models.py` - RecordingModel with FSM fields
- `database/automation_models.py` - ProcessingStage model
- Service layer - FSM validation

**Endpoints:**
```
POST /recordings/{id}/retry - Retry failed recording
POST /recordings/{id}/reset - Reset to INITIALIZED
GET /recordings/{id}/stages - Get processing stages
```

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ

---

## ADR-016: Database Performance Optimization

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
**–î–∞—Ç–∞:** –Ø–Ω–≤–∞—Ä—å 2026

### –†–µ—à–µ–Ω–∏–µ

–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ë–î —á–µ—Ä–µ–∑ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ N+1 queries, bulk operations –∏ eager loading.

### –ü—Ä–æ–±–ª–µ–º—ã

**–î–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:**
- N+1 queries: –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ—Å–µ—Ç–æ–≤ –≤ —Ü–∏–∫–ª–∞—Ö (1 –∑–∞–ø—Ä–æ—Å + N –∑–∞–ø—Ä–æ—Å–æ–≤)
- –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –≤ –ø–∞–º—è—Ç—å –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞
- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ eager loading –¥–ª—è –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –≤ batch –æ–ø–µ—Ä–∞—Ü–∏—è—Ö
- –ò–º–ø–æ—Ä—Ç—ã –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–π (anti-pattern)

### –†–µ—à–µ–Ω–∏–µ

**1. Bulk Operations:**
```python
# –î–æ: N –∑–∞–ø—Ä–æ—Å–æ–≤
for recording_id in recording_ids:
    recording = await repo.find_by_id(user_id, recording_id)

# –ü–æ—Å–ª–µ: 1 –∑–∞–ø—Ä–æ—Å
recordings = await repo.get_by_ids(user_id, recording_ids)
```

**2. Efficient Counting:**
```python
# –î–æ: –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π
jobs = await session.execute(select(AutomationJob).where(...))
count = len(jobs.scalars().all())

# –ü–æ—Å–ª–µ: database count
count = await session.scalar(
    select(func.count()).select_from(AutomationJob).where(...)
)
```

**3. Eager Loading:**
```python
# –î–æ: N+1 queries
recording = await session.get(Recording, id)
source = recording.source  # +1 query
preset = recording.outputs[0].preset  # +N queries

# –ü–æ—Å–ª–µ: 1 query with joins
stmt = (
    select(Recording)
    .options(
        selectinload(Recording.source).selectinload(SourceMetadata.input_source),
        selectinload(Recording.outputs).selectinload(OutputTarget.preset)
    )
    .where(Recording.id == id)
)
```

### –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏

**Repositories:**
- `recording_repos.py` - –¥–æ–±–∞–≤–ª–µ–Ω `get_by_ids()`, eager loading
- `template_repos.py` - –¥–æ–±–∞–≤–ª–µ–Ω `find_by_ids()` –¥–ª—è –ø—Ä–µ—Å–µ—Ç–æ–≤
- `automation_repos.py` - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω `count_user_jobs()`

**Tasks:**
- `upload.py` - —É—Å—Ç—Ä–∞–Ω–µ–Ω–∞ N+1 –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø—Ä–µ—Å–µ—Ç–æ–≤
- `processing.py` - —É—Å—Ç—Ä–∞–Ω–µ–Ω–∞ N+1 –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–µ—Å–µ—Ç–æ–≤

**Routers:**
- `recordings.py` - —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ 8 N+1 –ø—Ä–æ–±–ª–µ–º –≤ batch –æ–ø–µ—Ä–∞—Ü–∏—è—Ö
- `users.py` - —É–¥–∞–ª–µ–Ω –¥—É–±–ª–∏—Ä—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å

**Code Quality:**
- –í—Å–µ –∏–º–ø–æ—Ä—Ç—ã –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–æ–≤ (PEP8)
- –£–¥–∞–ª–µ–Ω—ã –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã –∏ –≤—ã–∑–æ–≤—ã

### –ú–µ—Ç—Ä–∏–∫–∏

**–î–æ:**
- Batch –æ–ø–µ—Ä–∞—Ü–∏—è (10 recordings): ~50 queries
- Count –æ–ø–µ—Ä–∞—Ü–∏—è: –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –≤ –ø–∞–º—è—Ç—å
- Nested relations: N+1 queries

**–ü–æ—Å–ª–µ:**
- Batch –æ–ø–µ—Ä–∞—Ü–∏—è (10 recordings): ~5 queries (-90%)
- Count –æ–ø–µ—Ä–∞—Ü–∏—è: 1 database query
- Nested relations: eager loading (1 query)

### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

**–§–∞–π–ª—ã:**
- `api/repositories/recording_repos.py`
- `api/repositories/template_repos.py`
- `api/repositories/automation_repos.py`
- `api/tasks/upload.py`
- `api/tasks/processing.py`
- `api/routers/recordings.py`
- `api/routers/users.py`

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (—è–Ω–≤–∞—Ä—å 2026)

---

## –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å—Ç–∞—Ç—É—Å–æ–≤

| ADR | Feature | Status | Priority | Notes |
|-----|---------|--------|----------|-------|
| ADR-010 | Automation | ‚úÖ Done | High | Celery Beat |
| ADR-011 | Async Processing | ‚úÖ Done | High | Celery Chains |
| ADR-012 | Quotas & Subscriptions | ‚úÖ Done | High | 4 plans |
| ADR-013 | Audit Logging | üöß Partial | Medium | Basic logging |
| ADR-014 | Notifications | üöß Partial | Low | Logging only |
| ADR-015 | FSM | ‚úÖ Done | High | Production-ready |
| ADR-016 | DB Optimization | ‚úÖ Done | High | N+1 eliminated |

---

## –°–º. —Ç–∞–∫–∂–µ

### –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- [TECHNICAL.md](TECHNICAL.md) - Automation system implementation
- [TECHNICAL.md](TECHNICAL.md) - Admin & Quota API
- [TECHNICAL.md](TECHNICAL.md) - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- [ADR_OVERVIEW.md](ADR_OVERVIEW.md) - –û—Å–Ω–æ–≤–Ω—ã–µ ADR —Ä–µ—à–µ–Ω–∏—è
- [DATABASE_DESIGN.md](DATABASE_DESIGN.md) - –°—Ö–µ–º—ã –ë–î

---

**–î–æ–∫—É–º–µ–Ω—Ç –æ–±–Ω–æ–≤–ª–µ–Ω:** –Ø–Ω–≤–∞—Ä—å 2026
**–°—Ç–∞—Ç—É—Å —Ñ–∏—á:** 4/6 fully done, 2/6 partial
